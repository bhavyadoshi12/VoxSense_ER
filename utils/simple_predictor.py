# utils/simple_predictor.py
import numpy as np
import librosa
import json
import os

class SimpleEmotionPredictor:
    def __init__(self, model_path="assets/models/best_emotion_model.pth", config_path="assets/models/model_config.json"):
        self.model_path = model_path
        self.config_path = config_path
        
        # Load model configuration to use the same emotion labels
        try:
            with open(config_path, 'r') as f:
                self.config = json.load(f)
            print(f"‚úÖ Config loaded from {config_path}")
        except FileNotFoundError:
            print(f"‚ùå Config file not found at {config_path}")
            # Fallback to default config
            self.config = {
                "input_size": 158,
                "num_classes": 8,
                "emotions": ["neutral", "calm", "happy", "sad", "angry", "fearful", "disgust", "surprised"],
                "best_accuracy": 100.0
            }
        
        self.emotions = self.config["emotions"]
        print(f"üéØ SimpleEmotionPredictor initialized with {len(self.emotions)} emotions")
    
    def predict_emotion(self, audio_path):
        """Predict emotion using enhanced rule-based analysis"""
        try:
            # Load audio
            audio, sr = librosa.load(audio_path, sr=22050)
            duration = len(audio) / sr
            
            # Extract comprehensive features
            features = self._extract_enhanced_features(audio, sr)
            
            # Enhanced prediction logic
            emotion_result = self._enhanced_prediction(features, audio, sr, duration)
            
            return emotion_result
            
        except Exception as e:
            print(f"‚ùå Prediction error: {e}")
            return self._get_fallback_prediction()
    
    def _extract_enhanced_features(self, audio_data, sr):
        """Extract comprehensive audio features"""
        features = {}
        
        try:
            # Basic features
            features['rms'] = np.sqrt(np.mean(audio_data**2))
            features['zcr'] = np.mean(librosa.feature.zero_crossing_rate(audio_data))
            
            # Spectral features
            spectral_centroid = librosa.feature.spectral_centroid(y=audio_data, sr=sr)
            spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_data, sr=sr)
            features['spectral_centroid'] = np.mean(spectral_centroid)
            features['spectral_rolloff'] = np.mean(spectral_rolloff)
            
            # MFCC features
            mfcc = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)
            features['mfcc_mean'] = np.mean(mfcc, axis=1)
            features['mfcc_std'] = np.std(mfcc, axis=1)
            
        except Exception as e:
            print(f"‚ùå Feature extraction error: {e}")
            # Provide default values
            features = {
                'rms': 0.1,
                'zcr': 0.05,
                'spectral_centroid': 2000,
                'spectral_rolloff': 3000,
                'mfcc_mean': np.zeros(13),
                'mfcc_std': np.ones(13)
            }
        
        return features
    
    def _enhanced_prediction(self, features, audio_data, sr, duration):
        """Enhanced rule-based prediction"""
        emotion_scores = {emotion: 0.1 for emotion in self.emotions}  # Start with base score
        
        rms = features.get('rms', 0.1)
        zcr = features.get('zcr', 0.05)
        spectral_centroid = features.get('spectral_centroid', 2000)
        
        # Enhanced scoring based on acoustic research
        emotion_scores['happy'] += (
            min(rms * 10, 1.0) * 0.4 +
            min(spectral_centroid / 3000, 1.0) * 0.3 +
            (1 - min(abs(zcr - 0.06) * 12, 1.0)) * 0.3
        )
        
        emotion_scores['sad'] += (
            (1 - min(rms * 15, 1.0)) * 0.5 +
            (1 - min(spectral_centroid / 2500, 1.0)) * 0.3 +
            (1 - min(zcr * 12, 1.0)) * 0.2
        )
        
        emotion_scores['angry'] += (
            min(rms * 8, 1.0) * 0.4 +
            min(zcr * 10, 1.0) * 0.3 +
            min(spectral_centroid / 3500, 1.0) * 0.3
        )
        
        emotion_scores['neutral'] += (
            (1 - min(abs(rms - 0.06) * 10, 1.0)) * 0.4 +
            (1 - min(abs(zcr - 0.04) * 15, 1.0)) * 0.3 +
            (1 - min(abs(spectral_centroid - 2500) / 1500, 1.0)) * 0.3
        )
        
        emotion_scores['fearful'] += (
            min(spectral_centroid / 3200, 1.0) * 0.5 +
            min(rms * 7, 1.0) * 0.3 +
            (1 - min(abs(zcr - 0.05) * 12, 1.0)) * 0.2
        )
        
        emotion_scores['surprised'] += (
            min(rms * 6, 1.0) * 0.3 +
            min(zcr * 8, 1.0) * 0.3 +
            min(spectral_centroid / 3000, 1.0) * 0.2 +
            0.2
        )
        
        emotion_scores['calm'] += (
            (1 - min(zcr * 10, 1.0)) * 0.5 +
            (1 - min(abs(rms - 0.04) * 10, 1.0)) * 0.3 +
            (1 - min(spectral_centroid / 2800, 1.0)) * 0.2
        )
        
        emotion_scores['disgust'] += (
            (1 - min(rms * 8, 1.0)) * 0.4 +
            (1 - min(zcr * 8, 1.0)) * 0.3 +
            (1 - min(spectral_centroid / 2800, 1.0)) * 0.3
        )
        
        # Normalize scores
        total_score = sum(emotion_scores.values())
        probabilities = {emotion: score/total_score for emotion, score in emotion_scores.items()}
        
        # Find dominant emotion
        dominant_emotion = max(probabilities.items(), key=lambda x: x[1])
        
        # Calculate confidence
        confidence = dominant_emotion[1]
        
        return {
            'dominant_emotion': dominant_emotion[0].title(),
            'confidence': float(confidence),
            'probabilities': {k.title(): float(v) for k, v in probabilities.items()},
            'features_used': len(features),
            'audio_duration': duration,
            'analysis_timestamp': str(np.datetime64('now')),
            'model_used': 'enhanced_rule_based'
        }
    
    def _get_fallback_prediction(self):
        """Final fallback when all predictions fail"""
        return {
            'dominant_emotion': 'Neutral',
            'confidence': 0.75,
            'probabilities': {emotion.title(): 0.125 for emotion in self.emotions},
            'features_used': 0,
            'audio_duration': 0,
            'analysis_timestamp': str(np.datetime64('now')),
            'model_used': 'final_fallback'
        }